{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "data = pd.read_csv('mcdonalds_market_segmentation.csv')"
      ],
      "metadata": {
        "id": "RyGM9XCVz0Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('mcdonalds_market_segmentation.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "id": "oPaBOISzz7bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('mcdonalds_market_segmentation.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "id": "sytjfIFe0Arh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the segmentation variables\n",
        "MD_x = data.iloc[:, :11]\n",
        "\n",
        "# Convert YES/NO to numeric binary (0 and 1)\n",
        "MD_x = (MD_x == \"Yes\").astype(int)\n",
        "\n",
        "# Perform Principal Components Analysis\n",
        "pca = PCA(n_components=2)\n",
        "MD_pca = pca.fit_transform(MD_x)\n",
        "\n",
        "# Create a scatter plot for the perceptual map\n",
        "plt.scatter(MD_pca[:, 0], MD_pca[:, 1], c='grey')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('Perceptual Map')\n",
        "\n",
        "# Add arrows for the original segmentation variables\n",
        "for i in range(len(pca.components_)):\n",
        "    plt.arrow(0, 0, pca.components_[i, 0], pca.components_[i, 1], color='red', alpha=0.5, width=0.005)\n",
        "    plt.text(pca.components_[i, 0], pca.components_[i, 1], MD_x.columns[i], color='red', fontsize=12)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jvnRvujU0D9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A.5 Step 5: Extracting Segments\n",
        "\n",
        "# A.5.1 Using k-Means\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Perform k-means analysis for 2 to 8 segments\n",
        "n_segments = range(2, 9)\n",
        "kmeans_solutions = {}\n",
        "for n in n_segments:\n",
        "    kmeans = KMeans(n_clusters=n, n_init=10, random_state=1234)\n",
        "    kmeans.fit(MD_x)\n",
        "    kmeans_solutions[str(n)] = kmeans\n",
        "\n",
        "# Relabel segment numbers for consistency\n",
        "for n in n_segments:\n",
        "    labels = kmeans_solutions[str(n)].labels_\n",
        "    unique_labels = np.unique(labels)\n",
        "    relabeled_labels = range(1, n + 1)\n",
        "    relabeling_dict = {unique_label: relabeled_label for unique_label, relabeled_label in zip(unique_labels, relabeled_labels)}\n",
        "    kmeans_solutions[str(n)].labels_ = np.vectorize(relabeling_dict.get)(labels)\n",
        "\n",
        "# Plot a scree plot to assess the number of segments\n",
        "inertia_values = [kmeans_solutions[str(n)].inertia_ for n in n_segments]\n",
        "plt.plot(n_segments, inertia_values, marker='o', linestyle='-', color='b')\n",
        "plt.xlabel('Number of Segments')\n",
        "plt.ylabel('Sum of Distances Within Segments')\n",
        "plt.title('Scree Plot')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kKxqSyIg0Ndu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A.5.2 Using Mixtures of Distributions\n",
        "\n",
        "# Calculate latent class analysis using a finite mixture of binary distributions\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert binary data to numerical labels (0 and 1)\n",
        "label_encoder = LabelEncoder()\n",
        "MD_x_encoded = MD_x.apply(lambda col: label_encoder.fit_transform(col))\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(1234)\n",
        "\n",
        "# Perform finite mixture model analysis for 2 to 8 segments\n",
        "n_components = range(2, 9)\n",
        "bic_values = []\n",
        "aic_values = []\n",
        "icl_values = []\n",
        "models = {}\n",
        "\n",
        "for n in n_components:\n",
        "    model = GaussianMixture(n_components=n, n_init=10, random_state=1234)\n",
        "    model.fit(MD_x_encoded)\n",
        "    bic_values.append(model.bic(MD_x_encoded))\n",
        "    aic_values.append(model.aic(MD_x_encoded))\n",
        "\n",
        "    models[str(n)] = model\n",
        "\n",
        "# Plot the information criteria values\n",
        "plt.plot(n_components, aic_values, marker='o', linestyle='-', color='b', label='AIC')\n",
        "plt.plot(n_components, bic_values, marker='o', linestyle='-', color='g', label='BIC')\n",
        "# Add ICL if available\n",
        "# plt.plot(n_components, icl_values, marker='o', linestyle='-', color='r', label='ICL')\n",
        "plt.xlabel('Number of Segments')\n",
        "plt.ylabel('Value of Information Criteria')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Information Criteria for Mixture Models')\n",
        "plt.show()\n",
        "\n",
        "# Compare mixture model with k-means model using cross-tabulation\n",
        "# Initialize mixture model using segment memberships from k-means\n",
        "kmeans_labels = clusters(MD_k4)\n",
        "mixture_model = GaussianMixture(n_components=4, n_init=10, random_state=1234)\n",
        "mixture_model.fit(MD_x_encoded)\n",
        "mixture_labels = mixture_model.predict(MD_x_encoded)\n",
        "\n",
        "# Create a cross-tabulation table\n",
        "cross_tab = pd.crosstab(kmeans_labels, mixture_labels)\n",
        "print(cross_tab)\n"
      ],
      "metadata": {
        "id": "VVqbHpNR0Vzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A.5.3 Using Mixtures of Regression Models\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert ordinal variable 'Like' to a numerical variable\n",
        "label_encoder = LabelEncoder()\n",
        "mcdonalds['Like.n'] = 6 - label_encoder.fit_transform(mcdonalds['Like'])\n",
        "\n",
        "# Define the independent variables (perceptions of McDonald's)\n",
        "independent_vars = mcdonalds.columns[1:12]\n",
        "\n",
        "# Fit a finite mixture of linear regression models with 2 components\n",
        "n_components = 2\n",
        "gmm = GaussianMixture(n_components=n_components, n_init=10, random_state=1234)\n",
        "\n",
        "# Create the dependent variable as a numpy array\n",
        "y = mcdonalds['Like.n'].values.reshape(-1, 1)\n",
        "\n",
        "# Fit the Gaussian Mixture Model\n",
        "gmm.fit(y)\n",
        "\n",
        "# Get the cluster labels\n",
        "cluster_labels = gmm.predict(y)\n",
        "\n",
        "# Create a linear regression model for each cluster\n",
        "regression_models = []\n",
        "for cluster in range(n_components):\n",
        "    cluster_indices = (cluster_labels == cluster)\n",
        "    X_cluster = mcdonalds.loc[cluster_indices, independent_vars]\n",
        "    y_cluster = mcdonalds.loc[cluster_indices, 'Like.n']\n",
        "    regression_model = LinearRegression().fit(X_cluster, y_cluster)\n",
        "    regression_models.append(regression_model)\n",
        "\n",
        "# Print coefficients for each cluster's linear regression model\n",
        "for cluster, model in enumerate(regression_models):\n",
        "    print(f\"Cluster {cluster + 1} (Component {cluster + 1})\")\n",
        "    print(\"Intercept:\", model.intercept_)\n",
        "    print(\"Coefficients:\", model.coef_)\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "42CixIeT0kFB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}